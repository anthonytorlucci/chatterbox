"""
research_context_grader

Retrieval grader for the research context generated by retriever nodes.
"""

# standard lib
import logging

# third party
from pydantic import BaseModel, Field

# langchain
from langchain_core.messages.ai import AIMessage
from langchain_core.prompts import (
    ChatPromptTemplate,
    PromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
    #MessagesPlaceholder
)

# langgraph

# local
from chatterbox.researcher_interface import (
    ResearcherInterface
)
from chatterbox.language_models import (
    LargeLanguageModelConfig,
    get_llm_model,
)
from chatterbox.nodes.pdf_context_retriever import PdfContextRetriever
from chatterbox.nodes.web_context_retriever import WebContextRetriever
from chatterbox.nodes.arxiv_context_retriever import ArxivContextRetriever
from chatterbox.nodes.vdbs_context_retriever import VdbsContextRetriever

SYSTEM_PROMPT = """
Objective:
Your task is to evaluate whether a retrieved document is relevant to a user's question. This involves assessing
both explicit keywords and the underlying semantic meaning of the content.

Criteria for Relevance:
1. **Keyword Match**: Check if the document contains words or phrases directly related to the user's query.
2. **Semantic Meaning**: Analyze if the document's main ideas, themes, or concepts align with the question, even
if exact keywords are absent.
3. **Contextual Understanding**: Consider the broader context of the document to determine its relevance beyond
surface-level terms.

Assessment Process:
- Begin by identifying key elements in the user's query.
- Examine the document for factual data, conceptual insights, or any information that directly or indirectly
addresses the query.
- Evaluate both explicit content and implied meanings to capture nuanced relevance.

Scoring:
Assign a binary score of 'yes' or 'no' based on your assessment. A 'yes' indicates relevance, while 'no'
suggests the document does not meaningfully contribute to answering the query. It does not need to be a stringent
test. The goal is to filter out erroneous retrievals.
"""

USER_PROMPT = """
Given the retrieved document:

\"""{document}\"""

and the research prompt:

\"""{research_prompt}\"""

grade the relevance of the document to the prompt.
"""

### Data model
class GradeDocuments(BaseModel):
    """Binary score for relevance check on retrieved documents."""

    binary_score: str = Field(
        description="Documents are relevant to the question, 'yes' or 'no'"
    )


### subclass ResearcherInterface

class ResearchContextGrader(ResearcherInterface):
    """
    A document relevance grading agent that evaluates retrieved documents against a research prompt.

    This agent is part of a multi-agent research system built with LangGraph. It determines
    whether documents retrieved by other agents (PDF, Web, Arxiv, or Vector DB retrievers) are
    relevant to the original research prompt. The agent uses a language model to perform binary
    relevance classification on each document.

    Attributes:
        NAME (str): Identifier for the agent ("research_context_grader")
        context_grader: A chain combining a chat prompt template with a structured LLM output

    Parameters:
        model_config (LargeLanguageModelConfig): Configuration for the language model used for grading

    Flow:
    1. Receives retrieved documents from a retriever agent
    2. Evaluates each document against the research prompt
    3. Assigns a binary relevance score ("yes"/"no") to each document
    4. Returns a filtered list containing only relevant documents

    The grading criteria are intentionally lenient - documents containing keywords or
    semantic meaning related to the research prompt are considered relevant. This helps
    filter out clearly irrelevant retrievals while maintaining potentially useful context.
    """
    NAME = "research_context_grader"
    def __init__(self,
        model_config: LargeLanguageModelConfig
    ):
        """
        Initialize the ResearchContextGrader with a language model configuration.

        This constructor sets up the grading chain by:
        1. Creating a structured language model for binary classification
        2. Defining system and human prompts for document relevance assessment
        3. Combining prompts into a chat template
        4. Creating the final grading chain

        Args:
            model_config (LargeLanguageModelConfig): Configuration object containing
                settings for the language model to be used for grading documents.
                This includes model name, parameters, and other relevant settings.

        Attributes:
            context_grader: A chain combining the chat prompt template with the
                structured language model output. This grader handles documents from all
                retriever types (PDF, Web, Arxiv, VDBs).
        """
        llm_grader = get_llm_model(model_config=model_config).with_structured_output(GradeDocuments)

        # Prompt
        sys_prompt=PromptTemplate(
            input_variables=[],
            template=SYSTEM_PROMPT
        )
        system_message_prompt = SystemMessagePromptTemplate(prompt=sys_prompt)

        human_prompt: PromptTemplate = PromptTemplate(
            input_variables=["document", "research_prompt"],
            template=USER_PROMPT
        )
        human_message_prompt = HumanMessagePromptTemplate(prompt=human_prompt)

        agent_prompt = ChatPromptTemplate.from_messages(
            [system_message_prompt, human_message_prompt])


        self.context_grader = agent_prompt | llm_grader


    def __call__(self, state: dict):
        """
        Determines whether the retrieved documents are relevant to the question.

        Args:
            state (dict): The current graph state

        Returns:
            state (dict): Updates documents key with only filtered relevant documents
        """
        logging.info("---CHECK DOCUMENT RELEVANCE TO QUESTION---")
        research_prompt:str = state.get("research_prompt", "")
        #calling_agent:str = state.get("calling_agent", "")
        match calling_agent := state.get("calling_agent", ""):
            case PdfContextRetriever.NAME:  # "pdf_context_retriever"
                documents = state.get("pdf_context", [])
            case WebContextRetriever.NAME:  # "web_context_retriever"
                documents = state.get("web_context", [])
            case ArxivContextRetriever.NAME:  # "arxiv_context_retriever"
                documents = state.get("arxiv_context", [])
            case VdbsContextRetriever.NAME:  # "vdbs_context_retriever"
                documents = state.get("vdbs_context", [])
            case _:
                documents = []

        filtered_docs = []
        if research_prompt and documents:
            # Score each doc
            filtered_docs = []
            for d in documents:
                score = self.context_grader.invoke(
                    {
                        "document": d.page_content,
                        "research_prompt": research_prompt
                    }
                )
                grade = score.binary_score
                if grade == "yes":
                    logging.info("---GRADE: DOCUMENT RELEVANT---")
                    filtered_docs.append(d)
                else:
                    logging.info("---GRADE: DOCUMENT NOT RELEVANT---")
                    continue
        if filtered_docs:
            ai_message = f"{len(filtered_docs)} relevant documents found."
        else:
            ai_message = "No relevant documents found."
        match calling_agent:
            case PdfContextRetriever.NAME:  # "pdf_context_retriever"
                return {
                    "calling_agent": PdfContextRetriever.NAME,
                    "pdf_context": filtered_docs,
                    "requires_pdf_context": False,
                    "messages": state["messages"] + [AIMessage(content=ai_message)]
                }
            case WebContextRetriever.NAME:  # "web_context_retriever"
                return {
                    "calling_agent": WebContextRetriever.NAME,
                    "web_context": filtered_docs,
                    "requires_web_context": False,
                    "messages": state["messages"] + [AIMessage(content=ai_message)]
                }
            case ArxivContextRetriever.NAME:  # "arxiv_context_retriever"
                return {
                    "calling_agent": ArxivContextRetriever.NAME,
                    "arxiv_context": filtered_docs,
                    "requires_arxiv_context": False,
                    "messages": state["messages"] + [AIMessage(content=ai_message)]
                }
            case VdbsContextRetriever.NAME:  # "vdbs_context_retriever"
                return {
                    "calling_agent": VdbsContextRetriever.NAME,
                    "vdbs_context": filtered_docs,
                    "requires_vdbs_context": False,
                    "messages": state["messages"] + [AIMessage(content=ai_message)]
                }
            case _:
                raise ValueError(f"Unknown calling agent: {calling_agent}")
